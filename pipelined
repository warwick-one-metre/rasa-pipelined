#!/usr/bin/env python3.4
#
# This file is part of rasa-pipelined.
#
# rasa-pipelined is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# rasa-pipelined is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with rasa-pipelined.  If not, see <http://www.gnu.org/licenses/>.

"""Daemon for the Warwick one-metre telescope frame pipeline"""

# pylint: disable=too-few-public-methods
# pylint: disable=no-self-use
# pylint: disable=broad-except
# pylint: disable=invalid-name
# pylint: disable=too-many-instance-attributes
# pylint: disable=too-many-locals
# pylint: disable=too-many-statements
# pylint: disable=too-many-lines
# pylint: disable=too-many-nested-blocks

import datetime
import json
import math
import os
import pathlib
import queue
import re
import shutil
import subprocess
import tempfile
import threading
import numpy
from astropy.io import fits
import astropy.table
import pyds9
from PIL import Image, ImageOps
import Pyro4
import sep
from warwick.observatory.common import (
    daemons,
    log,
    IP,
    helpers,
    TryLock)
from warwick.observatory.common.helpers import pyro_client_matches
from warwick.rasa.pipeline import CommandStatus
from warwick.rasa.focuser import FocuserStatus

# Set automatically when generating RPM package
SOFTWARE_VERSION = 'UNKNOWN'

# Maximum time to block the camera waiting to hand a frame to the processing thread
MAX_NOTIFY_WAIT = 10

# Timeout for telescope / environment status queries
STATUS_QUERY_TIMEOUT = 1

BASE_DATA_PATH = pathlib.Path('/home/ops/OBS_DATA/')

# Configuration cache
CONFIG_PATH = '/var/tmp/pipeline.json'

CONTROL_IPS = [IP.RASAMain]
NOTIFY_FRAME_IPS = [IP.RASAMain]

CAMERAS = ['RASA']

FOCUSERS = {
    'RASA': 1
}

# Time limit (seconds) allowed to solve the WCS coordinates of a preview frame
WCS_LIMIT = 4.0

# Maximum field size (arcmin)
# Note that this needs to account for the overscan too!
WCS_SCALE_HIGH = 13.7

# Maximum tcs ra/dec error (degrees)
WCS_SEARCH_RADIUS = 1.75

# Unbinned arcseconds per pixel
OBJECT_PLATESCALE = 1.66

# Minimum number of pixels for considering a source for FWHM estimation
OBJECT_MINPIX = 4

# Top/bottom margin (in px) to offset the annotation labels
ANNOTATION_LABEL_MARGIN = 90

ANNOTATION_LABEL = 'image; text {} {} #color=green font="helvetica 12 bold" text="{}" select=0'

ENVIRONMENT_KEYS = [
    ('goto_vaisala', 'temperature', 'EXTTEMP', '[deg c] temperature outside dome'),
    ('goto_vaisala', 'relative_humidity', 'EXTHUMD', '[%] humidity outside dome'),
    ('goto_vaisala', 'pressure', 'PRESSURE', '[hPa] air pressure'),
    ('goto_vaisala', 'wind_speed', 'WINDSPD', '[m/s] wind speed outside dome'),
    ('goto_vaisala', 'median_wind_speed', 'MEDWIND', '[m/s] median wind speed (last 20 min)'),
    ('superwasp', 'sky_temp', 'SKYTEMP', '[deg c] sky temperature'),
    ('goto_vaisala', 'dew_point_delta', 'DEWDELTA', '[deg c] temperature above dew point'),
    ('tng', 'dust', 'TNGDUST', '[ug/m3] TNG Dust measurement'),
    ('tng', 'seeing', 'TNGDIMM', '[arcsec] TNG DIMM seeing measurement'),
]

# TODO: Include environment daemon software versions, wind direction

# This should be kept in sync with the dictionary in pipeline

def rescale_image_data(data, clip_low, clip_high):
    """ Returns a normalised array where clip_low percent of the pixels are 0 and
        clip_high percent of the pixels are 255
    """
    high = numpy.percentile(data, clip_high)
    low = numpy.percentile(data, clip_low)
    scale = 255. / (high - low)
    data = numpy.clip(data, low, high)
    return scale * (data - low)

class PipelineDaemon:
    """Daemon interface for data pipeline"""
    def __init__(self):
        self._command_lock = threading.Lock()
        self._process_queue = {}
        for cam in CAMERAS:
            self._process_queue[cam] = queue.Queue(maxsize=1)
            thread = threading.Thread(target=self.__process_frames, args=[cam])
            thread.daemon = True
            thread.start()

        # Tuple of (camera, frame, messages)
        self._preview_data = queue.Queue()
        preview_thread = threading.Thread(target=self.__process_previews)
        preview_thread.daemon = True
        preview_thread.start()

        self._wcs_enabled = False
        self._fwhm_enabled = False
        self._intensity_stats_enabled = False
        self._dashboard_enabled = True
        self._compression_enabled = False

        # Information for building the output filename
        self._output_directory = BASE_DATA_PATH
        self._output_frame_prefix = 'unknown'

        self._frame_object = ''
        self._frame_type = 'JUNK'

        self._output_save_to_disk = {}
        self._ds9_preview_addresses = {}
        for cam in CAMERAS:
            self._output_save_to_disk[cam] = False
            self._ds9_preview_addresses[cam] = []

        # Min and max percentage thresholds to use for the preview pngs
        self._dashboard_min_threshold = 5
        self._dashboard_max_threshold = 95
        self._dashboard_thumb_size = 512

        try:
            with open(CONFIG_PATH, 'r') as infile:
                data = json.load(infile)

                self._wcs_enabled = data['wcs_enabled']
                self._fwhm_enabled = data['fwhm_enabled']
                self._intensity_stats_enabled = data['intensity_stats_enabled']
                self._dashboard_enabled = data['dashboard_enabled']
                self._compression_enabled = data['compression_enabled']

                # Information for building the output filename
                self._output_directory = pathlib.Path(data['output_directory'])
                self._output_frame_prefix = data['output_frame_prefix']

                self._frame_object = data['frame_object']
                self._frame_type = data['frame_type']

                for cam in CAMERAS:
                    self._output_save_to_disk[cam] = data[cam+'_output_save_to_disk']
                    self._ds9_preview_addresses[cam] = data[cam+'_ds9_preview_addresses']

                # Min and max percentage thresholds to use for the preview pngs
                self._dashboard_min_threshold = data['dashboard_min_threshold']
                self._dashboard_max_threshold = data['dashboard_max_threshold']
                self._dashboard_thumb_size = data['dashboard_thumb_size']
        except Exception as e:
            print('failed to load pipeline config with error: ')
            print(e)

    def __save_config(self):
        """Update the saved config cache on disk"""
        with open(CONFIG_PATH, 'w') as outfile:
            data = {
                'wcs_enabled': self._wcs_enabled,
                'fwhm_enabled': self._fwhm_enabled,
                'intensity_stats_enabled': self._intensity_stats_enabled,
                'dashboard_enabled': self._dashboard_enabled,
                'compression_enabled': self._compression_enabled,

                'output_directory': str(self._output_directory),
                'output_frame_prefix': self._output_frame_prefix,

                'frame_object': self._frame_object,
                'frame_type': self._frame_type,

                'dashboard_min_threshold': self._dashboard_min_threshold,
                'dashboard_max_threshold': self._dashboard_max_threshold,
                'dashboard_thumb_size': self._dashboard_thumb_size,
            }

            for cam in CAMERAS:
                data.update({
                    cam+'_output_save_to_disk': self._output_save_to_disk[cam],
                    cam+'_ds9_preview_addresses': self._ds9_preview_addresses[cam],
                })

            json.dump(data, outfile)

    def __process_previews(self, unregister_on_error=True):
        """Updates the ds9 preview windows with data from the main processing thread"""
        last_frame = None
        while True:
            try:
                # Block until a preview is available
                camera_id, frame, xpa_messages = self._preview_data.get()

                # We only care about the last entry
                try:
                    while True:
                        camera_id, frame, xpa_messages = self._preview_data.get(block=False)
                except queue.Empty:
                    pass

                for address in self._ds9_preview_addresses[camera_id][:]:
                    try:
                        p = pyds9.DS9(address, start=False, wait=1)
                        if frame is not None and frame != last_frame:
                            p.set_pyfits(fits.HDUList(frame))
                            last_frame = frame

                        if xpa_messages is not None:
                            for message in xpa_messages:
                                if isinstance(message, tuple):
                                    p.set(message[0], message[1])
                                else:
                                    p.set(message)
                    except Exception as e:
                        if unregister_on_error:
                            self._ds9_preview_addresses[camera_id].remove(address)
                            self.__save_config()
                            print('{}: unregistering preview {}: {}'.format(camera_id, address, e))
            except Exception as e:
                print('unexpected exception when processing ' + camera_id + ' preview')
                print(e)

    def __move_bscale_bzero(self, frame):
        """Moves the BSCALE and BZERO header keys to the start of the header
           to be grouped with the other image keywords"""
        frame.header.set('BSCALE', frame.header['BSCALE'], after='NAXIS2')
        frame.header.set('BZERO', frame.header['BZERO'], after='BSCALE')

    def __add_telescope_header(self, frame):
        """Queries the telescope status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---          TELESCOPE INFORMATION          --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        cards = [
            ('TELSWVER', 'tcs server software version'),
            ('TELSTATE', 'telescope status'),
            ('TELRA', 'telescope nominal J2000 RA'),
            ('TELDEC', 'telescope nominal J2000 Dec'),
            ('TELHA', 'telescope nominal HA'),
            ('TELRAD', '[deg] telescope nominal J2000 RA'),
            ('TELDECD', '[deg] telescope nominal J2000 Dec'),
            ('TELHAD', '[deg] telescope nominal HA'),
            ('ALTITUDE', '[deg] telescope altitude'),
            ('AZIMUTH', '[deg] telescope azimuth'),
            ('FOCSWVER', 'focus server software version'),
            ('FOCSTATE', 'focuser status'),
            ('FOCTEMP', '[deg] focuser temperature'),
            ('FOCPOS', '[steps] focuser position'),
            ('FOCTARG', '[steps] target focuser position'),
            ('SITELAT', 'telescope latitude (north)'),
            ('SITELONG', 'telescope longitude (east)'),
            ('SITEELEV', '[m] telescope elevation'),
        ]

        values = {}

        try:
            with daemons.rasa_telescope.connect(STATUS_QUERY_TIMEOUT) as teld:
                t = teld.report_status()
                values['TELSWVER'] = t['software_version']
                values['TELSTATE'] = t['state_label']
                if t['state'] != 0:
                    values['TELRA'] = helpers.sexagesimal(t['ra'] * 12 / math.pi)
                    values['TELDEC'] = helpers.sexagesimal(math.degrees(t['dec']))
                    values['TELHA'] = helpers.sexagesimal(t['ha'] * 12 / math.pi)
                    values['TELRAD'] = round(math.degrees(t['ra']), 3)
                    values['TELDECD'] = round(math.degrees(t['dec']), 3)
                    values['TELHAD'] = round(math.degrees(t['ha']), 3)
                    values['ALTITUDE'] = round(math.degrees(t['alt']), 3)
                    values['AZIMUTH'] = round(math.degrees(t['az']), 3)

                if 'site_latitude' in t:
                    values['SITELAT'] = helpers.sexagesimal(math.degrees(t['site_latitude']))
                    values['SITELONG'] = helpers.sexagesimal(math.degrees(t['site_longitude']))
                    values['SITEELEV'] = round(t['site_elevation'], 1)

        except Exception as e:
            print('failed to add telescope headers with error: ' + str(e))
            log.error('pipelined', 'Failed to query telescope metadata (' + str(e) + ')')

        try:
            with daemons.rasa_focus.connect(STATUS_QUERY_TIMEOUT) as focusd:
                f = focusd.report_status()
                values['FOCSWVER'] = f['software_version']

                c = f['channels'][FOCUSERS[h['INSTRARM']]]
                values['FOCSTATE'] = c['status_label']
                if c['status'] >= FocuserStatus.Idle:
                    values['FOCTEMP'] = c['temperature']
                    values['FOCPOS'] = c['current_steps']
                    values['FOCTARG'] = c['target_steps']
        except Exception as e:
            print('failed to add focuser headers with error: ' + str(e))
            log.error('pipelined', 'Failed to query focuser metadata (' + str(e) + ')')

        for c in cards:
            if c[0] in values:
                h.append(fits.Card(c[0], values[c[0]], c[1]), end=True)
            else:
                h.append(fits.Card('COMMENT', ' ' + c[0] + ' not available', ''), end=True)

        return h

    def __add_environment_header(self, frame):
        """Queries the environment status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---         ENVIRONMENT INFORMATION         --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        try:
            with daemons.rasa_environment.connect(STATUS_QUERY_TIMEOUT) as environment:
                data = environment.status()
                for (source, sensor, key, comment) in ENVIRONMENT_KEYS:
                    if source not in data or sensor not in data[source] \
                        or not data[source][sensor]['current']:
                        h.append(fits.Card('COMMENT', ' ' + key + ' not available', ''), end=True)
                    else:
                        h.append(fits.Card(key, data[source][sensor]['latest'], comment), end=True)

        except Exception as e:
            print('failed to add environment headers with error: ' + str(e))
            log.error('pipelined', 'Failed to query environment metadata (' + str(e) + ')')
        return h

    def __add_pipeline_header(self, camera_id, frame, filename):
        """Adds pipeline configuration to the frame header"""
        desc = fits.Card('COMMENT', ' ---               DATA PIPELINE               --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        try:
            frame.header.append(fits.Card('DPSWVER', SOFTWARE_VERSION,
                                          'data pipeline software version'), end=True)
            frame.header.append(fits.Card('FILESAVE', self._output_save_to_disk[camera_id],
                                          'image has been archived to disk'), end=True)
            frame.header.append(fits.Card('FILENAME', filename, 'archived image name'), end=True)
            frame.header.append(fits.Card('IMAGETYP', self._frame_type, 'frame type'), end=True)

            if self._frame_type == 'SCIENCE':
                frame.header.append(fits.Card('OBJECT', self._frame_object,
                                              'science target name'), end=True)

        except Exception as e:
            print('failed to add pipeline header with error: ' + str(e))

    def __add_wcs_header(self, frame, camera_id, objects):
        """Solves frame WCS and adds the appropriate header keys to the frame.
           Returns a list of xpa messages that can be given to __update_previews"""
        if objects is None or len(objects) <= 0:
            return []

        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']

        try:
            table_path = '/var/tmp/' + camera_id + '-scratch.xyls'
            try:
                os.remove(table_path)
            except OSError:
                pass

            astropy.table.Table(objects).write(table_path, format='fits')

            wcs_path = '/var/tmp/' + camera_id + '-scratch.wcs'
            try:
                os.remove(wcs_path)
            except OSError:
                pass

            args = [
                '/usr/local/astrometry/bin/solve-field',
                '--overwrite', '--no-plots',
                '--axy', 'none', '--rdls', 'none', '--match', 'none',
                '--corr', 'none', '--solved', 'none',
                '--scale-units', 'arcminwidth', '--scale-high', str(WCS_SCALE_HIGH),
                '--width', str(width), '--height', str(height),
                '--ra', frame.header['TELRA'], '--dec', frame.header['TELDEC'],
                '--radius', str(WCS_SEARCH_RADIUS), table_path]

            subprocess.check_call(args, timeout=WCS_LIMIT,
                                  stdout=subprocess.DEVNULL,
                                  stderr=subprocess.DEVNULL)

            wcs_data = ''
            wcs_ignore_cards = ['SIMPLE', 'BITPIX', 'NAXIS', 'EXTEND', 'DATE', 'IMAGEW', 'IMAGEH']
            comment = 'astrometry.net wcs solution'
            with open(wcs_path) as wcs_file:
                header = wcs_file.read()
                # ds9 will only accept newline-delimited keys
                # so we need to reformat the 80-character cards
                for line in [header[i:i+80] for i in range(0, len(header), 80)]:
                    key = line[0:8].strip()
                    if '=' in line and key not in wcs_ignore_cards:
                        card = fits.Card.fromstring(line)
                        value = line[9:].split('/')[0].strip()
                        wcs_data += key + ' = ' + value + '\n'

                        frame.header.append(fits.Card(card.keyword, card.value, comment), end=True)
            return [
                ('wcs replace', wcs_data),
                ('regions', ANNOTATION_LABEL.format(width / 5, -ANNOTATION_LABEL_MARGIN,
                                                    'WCS: solved'))
            ]
        except Exception as e:
            print('failed to update wcs with error: ' + str(e))
            return [('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN,
                                                        'WCS: failed'))]
        return []

    def __detect_objects(self, frame):
        """Subtracts the frame background then returns a numpy array of (x, y, flux, fwhm) for each
           object detected by sep"""
        try:
            if frame.header['SHUTTER'] == 'CLOSED':
                return numpy.zeros((0, 4))

            platescale = frame.header['CCD-XBIN'] * OBJECT_PLATESCALE

            # TODO: use Donuts
            image = frame.data.astype(float)
            bkg = sep.Background(image)
            subtracted = image - bkg

            thresh = 5 * bkg.globalrms
            raw_objects = sep.extract(subtracted, thresh)
            objects = []
            for star in raw_objects:
                # Discard spuriously small sources
                if star['npix'] < OBJECT_MINPIX:
                    continue

                x = star['x']
                y = star['y']
                a = star['a']
                b = star['b']
                theta = star['theta']
                kronrad, flag = sep.kron_radius(subtracted, x, y, a, b, theta, 6.0)
                if flag != 0:
                    continue

                flux, _, flag = sep.sum_ellipse(subtracted, x, y, a, b, theta, 2.5 * kronrad,
                                                subpix=0)
                if flag != 0:
                    continue

                r, flag = sep.flux_radius(subtracted, x, y, 6.0 * a, 0.5, normflux=flux, subpix=5)
                if flag != 0:
                    continue

                objects.append((x, y, flux, 2 * r * platescale))

            dtype = [('X', float), ('Y', float), ('FLUX', float), ('FWHM', float)]
            return numpy.array(objects, dtype=dtype)
        except Exception as e:
            print('failed to extract objects with error: ' + str(e))
            return numpy.zeros((0, 4))

    def __add_fwhm_header(self, frame, objects):
        """Adds the median fwhm to the frame header"""
        try:
            if objects is None or len(objects) <= 0:
                return

            median = round(numpy.median(objects['FWHM']), 2)
            frame.header.append(fits.Card('MEDFWHM', median, '[arcsec] median estimated FWHM'),
                                end=True)
            frame.header.append(fits.Card('FWHMCNT', len(objects),
                                          'number of sources used to estimate FWHM'), end=True)
        except Exception as e:
            print('failed to calculate fwhm with error: ' + str(e))

    def __add_intensity_stats_header(self, frame):
        """Estimates and the median PSF FWHM and returns a list of (x,y,r) tuples that can be
           used for the live preview overlays"""

        try:
            frame.header.append(fits.Card('MEANCNTS', round(numpy.mean(frame.data), 2),
                                          'mean frame counts'), end=True)
            frame.header.append(fits.Card('MEDCNTS', round(numpy.median(frame.data), 2),
                                          'median frame counts'), end=True)
            frame.header.append(fits.Card('STDCNTS', round(numpy.std(frame.data), 2),
                                          'standard deviation of frame counts'), end=True)
        except Exception as e:
            print('failed to calculate intensity stats with error: ' + str(e))

    def __generate_header_annotations(self, camera_id, frame, objects):
        """Returns the XPA commands to display the time and exposure on the live previews"""
        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']
        date = frame.header['DATE-OBS']
        exptime = frame.header['EXPTIME']
        arm = frame.header['INSTRARM']

        saved = 'SAVED' if self._output_save_to_disk[camera_id] else 'NOT SAVED'
        gps = 'GPS TIMESTAMP ' + frame.header['GPS-TMST'] + ' (' + str(frame.header['GPS-SATS'])
        gps += ' SATS ' + frame.header['GPS-FIX'] + ')'
        annotations = [
            ('regions', ANNOTATION_LABEL.format(width / 4, height + ANNOTATION_LABEL_MARGIN, date)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, height + ANNOTATION_LABEL_MARGIN,
                                                '{} @ {:.1f}s'.format(arm, exptime))),
            ('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN, gps)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, -ANNOTATION_LABEL_MARGIN, saved))
        ]

        if 'MEDFWHM' in frame.header:
            fwhm_label = ANNOTATION_LABEL.format(
                4 * width / 5, -ANNOTATION_LABEL_MARGIN,
                'FWHM: ' + str(frame.header['MEDFWHM']) + ' arcsec')
            annotations.append(('regions', fwhm_label))

        if objects is not None:
            for o in objects:
                cr = 'image; circle({},{},{}) #select=0 color=red'.format(o[0] + 1, o[1] + 1, o[3])
                annotations.append(('regions', cr))
        return annotations

    def __update_dashboard(self, camera_id, frame):
        try:
            # Trim overscan regions
            r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', frame.header['IMAG-RGN']).groups()
            data = frame.data[int(r[2])-1:int(r[3]), int(r[0])-1:int(r[1])]

            fwhm = -1 if 'MEDFWHM' not in frame.header else frame.header['MEDFWHM']
            metadata = {
                'date': frame.header['DATE-OBS'],
                'exptime': frame.header['EXPTIME'],
                'saved': frame.header['FILESAVE'],
                'filename': frame.header['FILENAME'],
                'fwhm': fwhm
            }

            scaled = rescale_image_data(data, self._dashboard_min_threshold,
                                        self._dashboard_max_threshold)
            png = Image.fromarray(scaled).convert('RGB')
            png = ImageOps.flip(png)

            png.save('/mnt/dashboard-generated/dashboard-' + camera_id + '.png', 'PNG',
                     clobber=True)
            png.thumbnail((self._dashboard_thumb_size, self._dashboard_thumb_size))
            png.save('/mnt/dashboard-generated/dashboard-' + camera_id + '-thumb.png', 'PNG',
                     clobber=True)
            with open('/mnt/dashboard-generated/dashboard-' + camera_id + '.json', 'w') as outfile:
                json.dump(metadata, outfile)
        except Exception as e:
            print('failed to generate dashboard preview with error: ' + str(e))
            log.error('pipelined', 'Failed to generate dashboard data (' + str(e) + ')')

    def __notify_opsd(self, frame):
        try:
            header = {}
            for card in frame.header.cards:
                if card.is_blank or not card.keyword or card.keyword == 'COMMENT':
                    continue

                header[card.keyword] = card.value

            with daemons.rasa_operations.connect() as ops:
                ops.notify_processed_frame(header)

        except Exception as e:
            print('failed to notify operations daemon of completed frame with error: ' + str(e))
            log.error('pipelined', 'Failed to notify operations daemon of completed' \
                                  ' frame (' + str(e) + ')')

    def __process_frames(self, camera_id):
        process_queue = self._process_queue[camera_id]
        while True:
            # Blocks until a frame is available for processing
            loadpath = process_queue.get()

            try:
                start = datetime.datetime.utcnow()
                with fits.open(loadpath) as hdulist:
                    # Take a copy of the primary HDU so that it remains
                    # available in memory after the file has been closed
                    # pylint: disable=no-member
                    frame = fits.PrimaryHDU(hdulist[0].data, hdulist[0].header)
                    # pylint: enable=no-member
                    print('loaded frame ' + loadpath)

                    steps = ['headers']
                    filename = ''
                    if self._output_save_to_disk[camera_id]:
                        date = datetime.datetime.strptime(frame.header['DATE-OBS'],
                                                          '%Y-%m-%dT%H:%M:%S.%f')
                        ext = '.fits.gz' if self._compression_enabled else '.fits'
                        filename = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + ext

                    self.__move_bscale_bzero(frame)
                    self.__add_telescope_header(frame)
                    self.__add_environment_header(frame)
                    self.__add_pipeline_header(camera_id, frame, filename)

                    if self._intensity_stats_enabled:
                        self.__add_intensity_stats_header(frame)
                        steps.append('intstats')

                    objects = None
                    if self._fwhm_enabled or self._wcs_enabled:
                        objects = self.__detect_objects(frame)
                        steps.append('objdetect')

                    if self._fwhm_enabled:
                        self.__add_fwhm_header(frame, objects)
                        steps.append('fwhm')

                    # Update previews before the relatively-slow WCS step
                    annotations = self.__generate_header_annotations(camera_id, frame, objects)
                    self._preview_data.put((camera_id, frame, annotations))

                    if self._wcs_enabled:
                        wcs = self.__add_wcs_header(frame, camera_id, objects)
                        self._preview_data.put((camera_id, frame, wcs))
                        steps.append('wcs')

                    if self._output_save_to_disk[camera_id]:
                        tmp = '.tmp.fits.gz' if self._compression_enabled else '.tmp.fits'
                        tmpname = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + tmp

                        tmppath = str(self._output_directory / tmpname)
                        savepath = str(self._output_directory / filename)

                        # Simulate an atomic write by writing to a temporary file then renaming
                        frame.writeto(tmppath, overwrite=True)
                        shutil.move(tmppath, savepath)

                        print('Saved frame ' + filename)
                        log.info('pipelined', 'Saved frame ' + filename)
                        steps.append('compress' if self._compression_enabled else 'save')
                        self.__save_config()

                    if self._dashboard_enabled:
                        self.__update_dashboard(camera_id, frame)
                        steps.append('dashboard')

                    self.__notify_opsd(frame)
                process_time = round((datetime.datetime.utcnow() - start).total_seconds(), 1)
                print('processed ' + loadpath + ' in ' + str(round(process_time, 2)) + 's (' \
                      + ', '.join(steps) + ')')

            except Exception as e:
                print('Unexpected exception while processing ' + loadpath + ': ' + str(e))
            finally:
                try:
                    os.remove(loadpath)
                    print('Deleting temporary frame: ' + loadpath)
                except Exception:
                    print('Failed to delete temporary frame: ' + loadpath)
                process_queue.task_done()

    @Pyro4.expose
    def notify_frame(self, camera_id, path):
        """Called by the camera daemons to notify that a new frame has been saved to disk"""
        if not pyro_client_matches(NOTIFY_FRAME_IPS):
            return CommandStatus.InvalidControlIP

        print(camera_id, path)
        if camera_id not in self._process_queue:
            raise Exception('Unknown camera id ' + camera_id)

        # Block until the processing thread has completed the previous frame.
        # We require a direct hand-off from the camera to the pipeline to prevent accidental
        # backlogs which would desync the real-time processing done by the processing thread.
        process_queue = self._process_queue[camera_id]
        wait_start = datetime.datetime.utcnow()
        process_queue.join()
        process_queue.put(path)
        wait = (datetime.datetime.utcnow() - wait_start).total_seconds()

        if wait > 0.1:
            print('WARNING: ' + camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')
            log.warning('pipelined', camera_id + ' camera blocked for ' + str(wait) + \
                's by pipeline')

        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive_directory(self, directory):
        """Sets the output frame directory"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            # Check that the directory exists and is writable
            try:
                path = pathlib.Path(directory).resolve()
                testfile = tempfile.TemporaryFile(dir=str(path))
                self._output_directory = path
                testfile.close()
            except Exception:
                return CommandStatus.DirectoryNotWritable

            log.info('pipelined', 'Frame archive directory set to ' + str(path))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_output_frame_prefix(self, prefix):
        """Sets the output frame prefix"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_frame_prefix = prefix

            log.info('pipelined', 'Frame prefix set to ' + prefix)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive(self, camera_id, enabled):
        """Enable or disable archiving to disk"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_save_to_disk[camera_id] = enabled
            log.info('pipelined', 'Frame archiving for ' + camera_id \
                                 + (' enabled' if enabled else ' disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def register_preview(self, camera_id, address):
        """Register a ds9 window for previews"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._ds9_preview_addresses[camera_id].append(address)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_object(self, object_name):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_object = object_name

            log.info('pipelined', 'Frame object set to ' + object_name)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_type(self, frame_type):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_type = frame_type

            log.info('pipelined', 'Frame type set to ' + frame_type)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_min_threshold(self, percent):
        """Sets the minimum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_min_threshold = percent
        log.info('pipelined', 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_max_threshold(self, percent):
        """Sets the maximum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_max_threshold = percent
        log.info('pipelined', 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_thumb_size(self, max_size):
        """Sets the maximum dimension of the web dashboard preview thumbnails"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_thumb_size = max_size
        log.info('pipelined', 'Dashboard preview thumbnail size set to ' + str(max_size) + ' px')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_wcs(self, enabled):
        """Enable or disable wcs solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._wcs_enabled = enabled
            log.info('pipelined', 'WCS solution ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_fwhm(self, enabled):
        """Enable or disable fwhm calculations"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._fwhm_enabled = enabled
            log.info('pipelined', 'FWHM calculation ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_intensity_stats(self, enabled):
        """Enable or disable intensity statistics solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._intensity_stats_enabled = enabled
            log.info('pipelined', 'Intensity statistics ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard(self, enabled):
        """Enable or disable dashboard updates"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._dashboard_enabled = enabled
            log.info('pipelined', 'Dashboard updates ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_compression(self, enabled):
        """Enable or disable gz compression"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._compression_enabled = enabled
            log.info('pipelined', 'Frame compression ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def configure(self, params):
        """Set pipeline configuration to the requested state
           params should be a dictionary with the following keys:
              path: Path where images should be saved
              prefix: Filename prefix for each image
              type: Science/Calibration/Junk/etc
              object: Object name to include for Science frames
              archive: Dictionary of instrument arm to bool for which images to archive
              wcs: Attempt to solve WCS coordinates (True/False)
              intstats: Calculate basic intensity statistics (True/False)
              fwhm: Calculate median FWHM from objects in the image (True/False)
              compression: Save frames with gz compression (True/False)
           Any properties not specified in params will be reset to its default
        """
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            try:
                path = pathlib.Path(params.get('path', BASE_DATA_PATH)).resolve()
                testfile = tempfile.TemporaryFile(dir=str(path))
                self._output_directory = path
                testfile.close()
            except Exception:
                return CommandStatus.DirectoryNotWritable

            log.info('pipelined', 'Frame archive directory set to ' + str(path))

            self._output_frame_prefix = params.get('prefix', 'unknown')
            log.info('pipelined', 'Frame prefix set to ' + self._output_frame_prefix)

            self._frame_type = params.get('type', 'JUNK')
            log.info('pipelined', 'Frame type set to ' + self._frame_type)

            self._frame_object = params.get('object', '')
            log.info('pipelined', 'Frame object set to ' + self._frame_object)

            for k, v in params.get('archive', {c: False for c in CAMERAS}).items():
                self._output_save_to_disk[k] = v
                log.info('pipelined', 'Frame archiving for ' + k + \
                    (' enabled' if v else ' disabled'))

            self._wcs_enabled = params.get('wcs', False)
            log.info('pipelined', 'WCS solution ' + \
                ('enabled' if self._wcs_enabled else 'disabled'))

            self._intensity_stats_enabled = params.get('intstats', False)
            log.info('pipelined', 'Intensity statistics ' + \
                ('enabled' if self._intensity_stats_enabled else 'disabled'))

            self._fwhm_enabled = params.get('fwhm', False)
            log.info('pipelined', 'FWHM calculation ' + \
                ('enabled' if self._fwhm_enabled else 'disabled'))

            self._compression_enabled = params.get('compression', False)
            log.info('pipelined', 'Frame compression ' + \
                ('enabled' if self._compression_enabled else 'disabled'))

            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def start_night(self):
        """Creates a new data directory for the current night and resets archive configuration"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            night = (datetime.datetime.utcnow() - datetime.timedelta(hours=12)).strftime('%Y%m%d')
            path = BASE_DATA_PATH / night
            try:
                os.makedirs(str(path))
                self._output_directory = path
            except Exception as e:
                print('failed to create night dir with exception:')
                print(e)
                return CommandStatus.NewDirectoryFailed

            self._output_frame_prefix = 'unknown'
            self._frame_object = ''
            self._frame_type = 'JUNK'

            for cam in CAMERAS:
                self._output_save_to_disk[cam] = False
            self._compression_enabled = False
            self.__save_config()

            log.info('pipelined', 'Started new night ' + night)
            return CommandStatus.Succeeded

    @Pyro4.expose
    def report_status(self):
        """Returns a dictionary containing the current pipeline state"""
        return {
            'wcs_enabled': self._wcs_enabled,
            'fwhm_enabled': self._fwhm_enabled,
            'intensity_stats_enabled': self._intensity_stats_enabled,
            'dashboard_enabled': self._dashboard_enabled,
            'compression_enabled': self._compression_enabled,

            'archive_enabled': self._output_save_to_disk,
            'archive_directory': str(self._output_directory),

            'dashboard_min_threshold': self._dashboard_min_threshold,
            'dashboard_max_threshold': self._dashboard_max_threshold,
            'dashboard_thumb_size': self._dashboard_thumb_size,

            'frame_type': self._frame_type,
            'frame_object': self._frame_object,
            'frame_prefix': self._output_frame_prefix
        }

if __name__ == '__main__':
    daemons.rasa_pipeline.launch(PipelineDaemon())
