#!/usr/bin/env python3.6
#
# This file is part of rasa-pipelined.
#
# rasa-pipelined is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# rasa-pipelined is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with rasa-pipelined.  If not, see <http://www.gnu.org/licenses/>.

"""Daemon for the Warwick one-metre telescope frame pipeline"""

# pylint: disable=too-few-public-methods
# pylint: disable=no-self-use
# pylint: disable=broad-except
# pylint: disable=invalid-name
# pylint: disable=too-many-instance-attributes
# pylint: disable=too-many-locals
# pylint: disable=too-many-statements
# pylint: disable=too-many-lines
# pylint: disable=too-many-nested-blocks
# pylint: disable=too-many-branches

import datetime
import json
import math
import os
import pathlib
import queue
import re
import shutil
import subprocess
import sys
import tempfile
import threading
import traceback
import numpy
from astropy.io import fits
import astropy.table
import pyds9
from PIL import Image, ImageOps
import Pyro4
import sep
from warwick.observatory.common import (
    daemons,
    log,
    IP,
    helpers,
    TryLock)
from warwick.observatory.common.helpers import pyro_client_matches
from warwick.rasa.pipeline import CommandStatus
from warwick.rasa.focuser import FocuserStatus

# Set automatically when generating RPM package
SOFTWARE_VERSION = 'UNKNOWN'

# Maximum time to block the camera waiting to hand a frame to the processing thread
MAX_NOTIFY_WAIT = 10

# Timeout for telescope / environment status queries
STATUS_QUERY_TIMEOUT = 1

BASE_DATA_PATH = pathlib.Path('/data/rasa/')

# Configuration cache
CONFIG_PATH = '/var/tmp/pipeline.json'

CONTROL_IPS = [IP.RASAMain]
NOTIFY_FRAME_IPS = [IP.RASAMain]

CAMERAS = ['RASA']

FOCUSERS = {
    'RASA': 1
}

LOG_NAME = 'rasa_pipelined'

# Time limit (seconds) allowed to solve the WCS coordinates of a preview frame
WCS_LIMIT = 4.0

# Arcseconds per pixel
WCS_SCALE_HIGH = 1.6
WCS_SCALE_LOW = 1.55

# Maximum tcs ra/dec error (degrees)
WCS_SEARCH_RADIUS = 1.75

# Unbinned arcseconds per pixel
OBJECT_PLATESCALE = 1.57

# Minimum number of pixels for considering a source for HFD estimation
OBJECT_MINPIX = 4

# Top/bottom margin (in px) to offset the annotation labels
ANNOTATION_LABEL_MARGIN = 100

ANNOTATION_LABEL = 'image; text {} {} #color=green font="helvetica 12 bold" text="{}" select=0'

ENVIRONMENT_KEYS = [
    ('goto_vaisala', 'temperature', 'EXTTEMP', '[deg c] temperature outside dome', 1),
    ('goto_vaisala', 'relative_humidity', 'EXTHUMD', '[%] humidity outside dome', 1),
    ('goto_vaisala', 'pressure', 'PRESSURE', '[hPa] air pressure', 1),
    ('goto_vaisala', 'wind_speed', 'WINDSPD', '[m/s] wind speed outside dome', 1),
    ('goto_vaisala', 'median_wind_speed', 'MEDWIND', '[m/s] median wind speed (last 20 min)', 1),
    ('goto_roomalert', 'dome2_internal_temp', 'DOMETEMP', '[deg c] temperature inside dome', 1),
    ('goto_roomalert', 'dome2_internal_humidity', 'DOMEHUMD', '[%] humidity inside dome', 1),
    ('superwasp', 'sky_temp', 'SKYTEMP', '[deg c] sky temperature', 1),
    ('goto_vaisala', 'dew_point_delta', 'DEWDELTA', '[deg c] temperature above dew point', 1),
    ('tng', 'dust', 'TNGDUST', '[ug/m3] TNG Dust measurement', 1),
    ('tng', 'seeing', 'TNGDIMM', '[arcsec] TNG DIMM seeing measurement', 2),
    ('robodimm', 'seeing', 'INGDIMMM', '[arcsec] ING RoboDIMM seeing measurement', 2),
]

# TODO: Include environment daemon software versions, wind direction

# This should be kept in sync with the dictionary in pipeline

def rescale_image_data(data, clip_low, clip_high):
    """ Returns a normalised array where clip_low percent of the pixels are 0 and
        clip_high percent of the pixels are 255
    """
    high = numpy.percentile(data, clip_high)
    low = numpy.percentile(data, clip_low)
    scale = 255. / (high - low)
    data = numpy.clip(data, low, high)
    return scale * (data - low)

def create_float_card(key, value, comment, places):
    """Create a fits.Card instance with a float value
       rounded to a specified number of significant figures
    """
    fmt = '{:8s}= {:.0' + str(places) + 'f}'
    card = fits.Card.fromstring(fmt.format(key, value))
    card.comment = comment
    return card

class PipelineDaemon:
    """Daemon interface for data pipeline"""
    def __init__(self):
        self._command_lock = threading.Lock()
        self._process_queue = {}
        for cam in CAMERAS:
            self._process_queue[cam] = queue.Queue(maxsize=1)
            thread = threading.Thread(target=self.__process_frames, args=[cam])
            thread.daemon = True
            thread.start()

        # Tuple of (camera, frame, messages)
        self._preview_data = queue.Queue()
        preview_thread = threading.Thread(target=self.__process_previews)
        preview_thread.daemon = True
        preview_thread.start()

        self._wcs_enabled = False
        self._hfd_enabled = False
        self._intensity_stats_enabled = False
        self._dashboard_enabled = True
        self._compression_enabled = False

        # Information for building the output filename
        self._output_directory = BASE_DATA_PATH
        self._output_frame_prefix = 'unknown'

        self._frame_object = ''
        self._frame_type = 'JUNK'

        self._output_save_to_disk = {}
        self._ds9_preview_addresses = {}
        for cam in CAMERAS:
            self._output_save_to_disk[cam] = False
            self._ds9_preview_addresses[cam] = []

        # Min and max percentage thresholds to use for the preview pngs
        self._dashboard_min_threshold = 5
        self._dashboard_max_threshold = 95
        self._dashboard_thumb_size = 1024
        self._dashboard_clip_size = 1024

        try:
            with open(CONFIG_PATH, 'r') as infile:
                data = json.load(infile)

                self._wcs_enabled = data.get('wcs_enabled', self._wcs_enabled)
                self._hfd_enabled = data.get('hfd_enabled', self._hfd_enabled)
                self._intensity_stats_enabled = data.get('intensity_stats_enabled',
                                                         self._intensity_stats_enabled)
                self._dashboard_enabled = data.get('dashboard_enabled', self._dashboard_enabled)
                self._compression_enabled = data.get('compression_enabled',
                                                     self._compression_enabled)

                # Information for building the output filename
                self._output_directory = pathlib.Path(data.get('output_directory',
                                                               self._output_directory))
                self._output_frame_prefix = data.get('output_frame_prefix',
                                                     self._output_frame_prefix)

                self._frame_object = data.get('frame_object', self._frame_object)
                self._frame_type = data.get('frame_type', self._frame_type)

                for cam in CAMERAS:
                    self._output_save_to_disk[cam] = data.get(cam+'_output_save_to_disk',
                                                              self._output_save_to_disk[cam])
                    self._ds9_preview_addresses[cam] = data.get(cam+'_ds9_preview_addresses',
                                                                self._ds9_preview_addresses[cam])

                # Min and max percentage thresholds to use for the preview pngs
                self._dashboard_min_threshold = data.get('dashboard_min_threshold',
                                                         self._dashboard_min_threshold)
                self._dashboard_max_threshold = data.get('dashboard_max_threshold',
                                                         self._dashboard_max_threshold)
                self._dashboard_thumb_size = data.get('dashboard_thumb_size',
                                                      self._dashboard_thumb_size)
                self._dashboard_clip_size = data.get('dashboard_clip_size',
                                                     self._dashboard_clip_size)
        except Exception:
            print('failed to load pipeline config with error:')
            traceback.print_exc(file=sys.stdout)

    def __save_config(self):
        """Update the saved config cache on disk"""
        with open(CONFIG_PATH, 'w') as outfile:
            data = {
                'wcs_enabled': self._wcs_enabled,
                'hfd_enabled': self._hfd_enabled,
                'intensity_stats_enabled': self._intensity_stats_enabled,
                'dashboard_enabled': self._dashboard_enabled,
                'compression_enabled': self._compression_enabled,

                'output_directory': str(self._output_directory),
                'output_frame_prefix': self._output_frame_prefix,

                'frame_object': self._frame_object,
                'frame_type': self._frame_type,

                'dashboard_min_threshold': self._dashboard_min_threshold,
                'dashboard_max_threshold': self._dashboard_max_threshold,
                'dashboard_thumb_size': self._dashboard_thumb_size,
                'dashboard_clip_size': self._dashboard_clip_size,
            }

            for cam in CAMERAS:
                data.update({
                    cam+'_output_save_to_disk': self._output_save_to_disk[cam],
                    cam+'_ds9_preview_addresses': self._ds9_preview_addresses[cam],
                })

            json.dump(data, outfile)

    def __set_archive_directory(self, path):
        """Attempts to set the output data directory
           If path is 'default' a YYYYMMDD night directory will be created in the BASE_DATA_PATH
           otherwise, the given path will be checked to ensure it is writable
           Returns a CommandStatus indicating the result
        """
        try:
            if path == 'default':
                # Default to a night directory in the base data dir
                # Directory will be created if required
                night = (datetime.datetime.utcnow() - datetime.timedelta(hours=12))
                path = BASE_DATA_PATH / night.strftime('%Y%m%d')
                try:
                    path.mkdir(parents=True)
                except FileExistsError:
                    pass
                except Exception:
                    print('failed to create night dir with exception:')
                    traceback.print_exc(file=sys.stdout)
                    return CommandStatus.NewDirectoryFailed
            else:
                # Custom directories are expected to already exist
                path = pathlib.Path(path).resolve()

            testfile = tempfile.TemporaryFile(dir=str(path))
            self._output_directory = path
            testfile.close()
            return CommandStatus.Succeeded
        except Exception:
            return CommandStatus.DirectoryNotWritable

    def __process_previews(self, unregister_on_error=True):
        """Updates the ds9 preview windows with data from the main processing thread"""
        last_frame = None
        while True:
            try:
                # Block until a preview is available
                camera_id, frame, xpa_messages = self._preview_data.get()

                # We only care about the last entry
                try:
                    while True:
                        camera_id, frame, xpa_messages = self._preview_data.get(block=False)
                except queue.Empty:
                    pass

                for address in self._ds9_preview_addresses[camera_id][:]:
                    try:
                        p = pyds9.DS9(address, start=False, wait=1)
                        if frame is not None and frame != last_frame:
                            p.set_pyfits(fits.HDUList(frame))
                            last_frame = frame

                        if xpa_messages is not None:
                            for message in xpa_messages:
                                if isinstance(message, tuple):
                                    p.set(message[0], message[1])
                                else:
                                    p.set(message)
                    except Exception as e:
                        if unregister_on_error:
                            self._ds9_preview_addresses[camera_id].remove(address)
                            self.__save_config()
                            print('{}: unregistering preview {}: {}'.format(camera_id, address, e))
            except Exception:
                print('unexpected exception when processing ' + camera_id + ' preview')
                traceback.print_exc(file=sys.stdout)

    def __move_bscale_bzero(self, frame):
        """Moves the BSCALE and BZERO header keys to the start of the header
           to be grouped with the other image keywords"""
        frame.header.set('BSCALE', frame.header['BSCALE'], after='NAXIS2')
        frame.header.set('BZERO', frame.header['BZERO'], after='BSCALE')

    def __add_telescope_header(self, frame):
        """Queries the telescope status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---          TELESCOPE INFORMATION          --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        cards = [
            ('TELSWVER', 'tcs server software version'),
            ('TELSTATE', 'telescope status'),
            ('TELRA', 'telescope nominal J2000 RA'),
            ('TELDEC', 'telescope nominal J2000 Dec'),
            ('TELHA', 'telescope nominal HA'),
            ('TELRAD', '[deg] telescope nominal J2000 RA', 3),
            ('TELDECD', '[deg] telescope nominal J2000 Dec', 3),
            ('TELHAD', '[deg] telescope nominal HA', 3),
            ('ALTITUDE', '[deg] telescope altitude', 3),
            ('AZIMUTH', '[deg] telescope azimuth', 3),
            ('SITELAT', 'telescope latitude (north)'),
            ('SITELONG', 'telescope longitude (east)'),
            ('SITEELEV', '[m] telescope elevation'),
            ('FOCSWVER', 'focus server software version'),
            ('FOCSTATE', 'focuser status'),
            ('FOCTEMP', '[deg] focuser temperature', 1),
            ('FOCPOS', '[steps] focuser position'),
            ('FOCTARG', '[steps] target focuser position'),
        ]

        values = {}

        try:
            with daemons.rasa_telescope.connect(STATUS_QUERY_TIMEOUT) as teld:
                t = teld.report_status()
                values['TELSWVER'] = t['software_version']
                values['TELSTATE'] = t['state_label']
                if t['state'] != 0:
                    harad = t['lst'] - t['ra']
                    while harad > math.pi:
                        harad -= 2*math.pi
                    while harad < -math.pi:
                        harad += 2*math.pi

                    values['TELRA'] = helpers.sexagesimal(t['ra'] * 12 / math.pi)
                    values['TELDEC'] = helpers.sexagesimal(math.degrees(t['dec']))
                    values['TELHA'] = helpers.sexagesimal(harad * 12 / math.pi)
                    values['TELRAD'] = math.degrees(t['ra'])
                    values['TELDECD'] = math.degrees(t['dec'])
                    values['TELHAD'] = math.degrees(harad)
                    values['ALTITUDE'] = math.degrees(t['alt'])
                    values['AZIMUTH'] = math.degrees(t['az'])

                if 'site_latitude' in t:
                    values['SITELAT'] = helpers.sexagesimal(math.degrees(t['site_latitude']))
                    values['SITELONG'] = helpers.sexagesimal(math.degrees(t['site_longitude']))
                    values['SITEELEV'] = int(t['site_elevation'])

        except Exception as e:
            print('failed to add telescope headers with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(LOG_NAME, 'Failed to query telescope metadata (' + str(e) + ')')

        try:
            with daemons.rasa_focus.connect(STATUS_QUERY_TIMEOUT) as focusd:
                f = focusd.report_status()
                values['FOCSWVER'] = f['software_version']

                c = f['channels'][FOCUSERS[h['INSTRARM']]]
                values['FOCSTATE'] = c['status_label']
                if c['status'] >= FocuserStatus.Idle:
                    values['FOCTEMP'] = c['temperature']
                    values['FOCPOS'] = c['current_steps']
                    values['FOCTARG'] = c['target_steps']
        except Exception as e:
            print('failed to add focuser headers with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(LOG_NAME, 'Failed to query focuser metadata (' + str(e) + ')')

        for c in cards:
            if c[0] in values:
                if len(c) > 2:
                    h.append(create_float_card(c[0], values[c[0]], c[1], c[2]), end=True)
                else:
                    h.append(fits.Card(c[0], values[c[0]], c[1]), end=True)
            else:
                h.append(fits.Card('COMMENT', ' ' + c[0] + ' not available', ''), end=True)

        return h

    def __add_environment_header(self, frame):
        """Queries the environment status and adds the appropriate header keys to the frame"""
        h = frame.header
        desc = fits.Card('COMMENT', ' ---         ENVIRONMENT INFORMATION         --- ')
        h.append(fits.Card(None, None), end=True)
        h.append(desc, end=True)

        try:
            with daemons.observatory_environment.connect(STATUS_QUERY_TIMEOUT) as environment:
                data = environment.status()
                for (source, sensor, key, comment, places) in ENVIRONMENT_KEYS:
                    sensor_data = data.get(source, {}).get('parameters', {}).get(sensor, {})
                    if sensor_data and sensor_data.get('current', False):
                        h.append(create_float_card(key, sensor_data['latest'], comment, places),
                                 end=True)
                    else:
                        h.append(fits.Card('COMMENT', ' ' + key + ' not available', ''), end=True)

        except Exception as e:
            print('failed to add environment headers with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(LOG_NAME, 'Failed to query environment metadata (' + str(e) + ')')
        return h

    def __add_pipeline_header(self, camera_id, frame, filename):
        """Adds pipeline configuration to the frame header"""
        desc = fits.Card('COMMENT', ' ---               DATA PIPELINE               --- ')
        frame.header.append(fits.Card(None, None), end=True)
        frame.header.append(desc, end=True)

        try:
            frame.header.append(fits.Card('DPSWVER', SOFTWARE_VERSION,
                                          'data pipeline software version'), end=True)
            frame.header.append(fits.Card('FILESAVE', self._output_save_to_disk[camera_id],
                                          'image has been archived to disk'), end=True)
            frame.header.append(fits.Card('FILENAME', filename, 'archived image name'), end=True)
            frame.header.append(fits.Card('IMAGETYP', self._frame_type, 'frame type'), end=True)

            if self._frame_type == 'SCIENCE':
                frame.header.append(fits.Card('OBJECT', self._frame_object,
                                              'science target name'), end=True)

        except Exception:
            print('failed to add pipeline header with error:')
            traceback.print_exc(file=sys.stdout)

    def __add_wcs_header(self, frame, camera_id, objects):
        """Solves frame WCS and adds the appropriate header keys to the frame.
           Returns a list of xpa messages that can be given to __update_previews"""
        if objects is None or len(objects) <= 0:
            return []

        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']

        try:
            table_path = '/var/tmp/' + camera_id + '-scratch.xyls'
            try:
                os.remove(table_path)
            except OSError:
                pass

            astropy.table.Table(objects).write(table_path, format='fits')

            wcs_path = '/var/tmp/' + camera_id + '-scratch.wcs'
            try:
                os.remove(wcs_path)
            except OSError:
                pass

            args = [
                '/usr/local/astrometry/bin/solve-field',
                '--overwrite', '--no-plots',
                '--axy', 'none', '--rdls', 'none', '--match', 'none',
                '--corr', 'none', '--solved', 'none',
                '--scale-units', 'arcsecperpix', '--scale-high', str(WCS_SCALE_HIGH),
                '--scale-low', str(WCS_SCALE_LOW), '--width', str(width), '--height', str(height),
                '--ra', frame.header['TELRA'], '--dec', frame.header['TELDEC'],
                '--radius', str(WCS_SEARCH_RADIUS), table_path]

            subprocess.check_call(args, timeout=WCS_LIMIT,
                                  stdout=subprocess.DEVNULL,
                                  stderr=subprocess.DEVNULL)

            wcs_data = ''
            wcs_ignore_cards = ['SIMPLE', 'BITPIX', 'NAXIS', 'EXTEND', 'DATE', 'IMAGEW', 'IMAGEH']
            comment = 'astrometry.net wcs solution'
            with open(wcs_path) as wcs_file:
                header = wcs_file.read()
                # ds9 will only accept newline-delimited keys
                # so we need to reformat the 80-character cards
                for line in [header[i:i+80] for i in range(0, len(header), 80)]:
                    key = line[0:8].strip()
                    if '=' in line and key not in wcs_ignore_cards:
                        card = fits.Card.fromstring(line)
                        value = line[9:].split('/')[0].strip()
                        wcs_data += key + ' = ' + value + '\n'

                        frame.header.append(fits.Card(card.keyword, card.value, comment), end=True)
            return [
                ('wcs replace', wcs_data),
                ('regions', ANNOTATION_LABEL.format(3 * width / 4, -5 * ANNOTATION_LABEL_MARGIN,
                                                    'WCS: SOLVED'))
            ]
        except Exception:
            print('failed to update wcs with error:')
            traceback.print_exc(file=sys.stdout)
            return [('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN,
                                                        'WCS: FAILED'))]
        return []

    def __detect_objects(self, frame):
        """Subtracts the frame background then returns a numpy array of (x, y, flux, hfd) for each
           object detected by sep"""
        try:
            if frame.header['SHUTTER'] == 'CLOSED':
                return numpy.zeros((0, 4))

            platescale = frame.header['CCD-XBIN'] * OBJECT_PLATESCALE

            # TODO: use Donuts
            image = frame.data.astype(float)
            bkg = sep.Background(image)
            subtracted = image - bkg

            thresh = 5 * bkg.globalrms
            raw_objects = sep.extract(subtracted, thresh)
            objects = []
            for star in raw_objects:
                # Discard spuriously small sources
                if star['npix'] < OBJECT_MINPIX:
                    continue

                x = star['x']
                y = star['y']
                a = star['a']
                b = star['b']

                try:
                    theta = star['theta']
                    kronrad, flag = sep.kron_radius(subtracted, x, y, a, b, theta, 6.0)
                    if flag != 0:
                        continue

                    flux, _, flag = sep.sum_ellipse(subtracted, x, y, a, b, theta, 2.5 * kronrad,
                                                    subpix=0)
                    if flag != 0:
                        continue

                    r, flag = sep.flux_radius(subtracted, x, y, 6.0 * a, 0.5,
                                              normflux=flux, subpix=5)
                    if flag != 0:
                        continue

                    objects.append((x, y, flux, 2 * r * platescale))
                except Exception:
                    # Ignore errors in individual objects
                    pass

            dtype = [('X', float), ('Y', float), ('FLUX', float), ('HFD', float)]

            # HACK: Limit object detection to 500 brightest objects
            # This lets us get sensible focus measurements for now
            # at a tradeoff of WCS, which isn't working yet anyway
            return numpy.array(sorted(objects, key=lambda o: -o[2])[:500], dtype=dtype)
        except Exception:
            print('failed to extract objects with error:')
            traceback.print_exc(file=sys.stdout)
            return numpy.zeros((0, 4))

    def __add_hfd_header(self, frame, objects):
        """Adds the median half-flux diameter to the frame header"""
        try:
            if objects is None or len(objects) <= 0:
                return

            median = round(numpy.median(objects['HFD']), 2)
            frame.header.append(
                create_float_card('MEDHFD', median,
                                  '[arcsec] median estimated half-flux diameter', 1), end=True)
            frame.header.append(
                fits.Card('HFDCNT', len(objects),
                          'number of sources used to estimate the HFD'), end=True)
        except Exception:
            print('failed to calculate HFD with error:')
            traceback.print_exc(file=sys.stdout)

    def __add_intensity_stats_header(self, frame):
        """Adds the frame intensity to the frame header"""

        try:
            frame.header.append(create_float_card('MEANCNTS', numpy.mean(frame.data),
                                                  'mean frame counts', 2), end=True)
            frame.header.append(create_float_card('MEDCNTS', numpy.median(frame.data),
                                                  'median frame counts', 2), end=True)
            frame.header.append(create_float_card('STDCNTS', numpy.std(frame.data),
                                                  'standard deviation of frame counts', 2),
                                end=True)
        except Exception:
            print('failed to calculate intensity stats with error:')
            traceback.print_exc(file=sys.stdout)

    def __generate_header_annotations(self, camera_id, frame, objects):
        """Returns the XPA commands to display the time and exposure on the live previews"""
        width = frame.header['NAXIS1']
        height = frame.header['NAXIS2']
        date = frame.header['DATE-OBS']
        exptime = frame.header['EXPTIME']
        arm = frame.header['INSTRARM']

        saved = 'SAVED' if self._output_save_to_disk[camera_id] else 'NOT SAVED'
        gps = 'GPS TIMESTAMP ' + frame.header['GPS-TMST']
        gps_sats = ' ({} SATS {})'.format(frame.header['GPS-SATS'], frame.header['GPS-FIX'])
        annotations = [
            ('regions', ANNOTATION_LABEL.format(width / 4, height + ANNOTATION_LABEL_MARGIN, date)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, height + ANNOTATION_LABEL_MARGIN,
                                                '{} @ {:.1f}s'.format(arm, exptime))),
            ('regions', ANNOTATION_LABEL.format(width / 4, -ANNOTATION_LABEL_MARGIN, gps)),
            ('regions', ANNOTATION_LABEL.format(width / 4, -3 * ANNOTATION_LABEL_MARGIN, gps_sats)),
            ('regions', ANNOTATION_LABEL.format(3 * width / 4, -ANNOTATION_LABEL_MARGIN, saved))
        ]

        if 'MEDHFD' in frame.header:
            hfd_label = ANNOTATION_LABEL.format(
                3 * width / 4, -3 * ANNOTATION_LABEL_MARGIN,
                'HFD: ' + str(frame.header['MEDHFD']) + ' arcsec')
            annotations.append(('regions', hfd_label))

        if objects is not None:
            for o in objects:
                cr = 'image; circle({},{},{}) #select=0 color=red'.format(o[0] + 1, o[1] + 1, o[3])
                annotations.append(('regions', cr))
        return annotations

    def __update_dashboard(self, camera_id, frame):
        try:
            # Trim overscan regions
            r = re.search(r'^\[(\d+):(\d+),(\d+):(\d+)\]$', frame.header['IMAG-RGN']).groups()
            data = frame.data[int(r[2])-1:int(r[3]), int(r[0])-1:int(r[1])]
            ds = numpy.shape(data)

            obj = frame.header['IMAGETYP']
            if frame.header['IMAGETYP'] == 'SCIENCE' and frame.header['OBJECT']:
                obj = frame.header['OBJECT']

            hfd = -1 if 'MEDHFD' not in frame.header else frame.header['MEDHFD']
            medcnts = -1 if 'MEDCNTS' not in frame.header else frame.header['MEDCNTS']
            metadata = {
                'object': obj,
                'date': frame.header['DATE-OBS'],
                'exptime': frame.header['EXPTIME'],
                'saved': frame.header['FILESAVE'],
                'filename': frame.header['FILENAME'],
                'size': [ds[1], ds[0]],
                'clipsize': self._dashboard_clip_size,
                'hfd': hfd,
                'medcnts': medcnts
            }

            scaled = rescale_image_data(data, self._dashboard_min_threshold,
                                        self._dashboard_max_threshold)
            png = Image.fromarray(scaled).convert('RGB')
            png = ImageOps.flip(png)

            png.thumbnail((self._dashboard_thumb_size, self._dashboard_thumb_size))
            png.save('/mnt/dashboard-generated/dashboard-' + camera_id + '-thumb.jpg', 'JPEG',
                     quality=80, optimize=True, progressive=True, clobber=True)

            # Clip the central region from the image
            cx1 = (ds[0] - self._dashboard_clip_size) // 2
            cx2 = cx1 + self._dashboard_clip_size
            cy1 = (ds[1] - self._dashboard_clip_size) // 2
            cy2 = cy1 + self._dashboard_clip_size

            clipped = rescale_image_data(data[cx1:cx2, cy1:cy2], self._dashboard_min_threshold,
                                         self._dashboard_max_threshold)
            png = Image.fromarray(clipped).convert('RGB')
            png = ImageOps.flip(png)
            png.save('/mnt/dashboard-generated/dashboard-' + camera_id + '-clip.jpg', 'JPEG',
                     quality=40, optimize=True, progressive=True, clobber=True)

            with open('/mnt/dashboard-generated/dashboard-' + camera_id + '.json', 'w') as outfile:
                json.dump(metadata, outfile)
        except Exception as e:
            print('failed to generate dashboard preview with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(LOG_NAME, 'Failed to generate dashboard data (' + str(e) + ')')

    def __notify_opsd(self, frame):
        try:
            header = {}
            for card in frame.header.cards:
                if card.is_blank or not card.keyword or card.keyword == 'COMMENT':
                    continue

                header[card.keyword] = card.value

            with daemons.rasa_operations.connect() as ops:
                ops.notify_processed_frame(header)

        except Exception as e:
            print('failed to notify operations daemon of completed frame with error:')
            traceback.print_exc(file=sys.stdout)
            log.error(LOG_NAME, 'Failed to notify operations daemon of completed' \
                                ' frame (' + str(e) + ')')

    def __process_frames(self, camera_id):
        process_queue = self._process_queue[camera_id]
        while True:
            # Blocks until a frame is available for processing
            loadpath = process_queue.get()

            try:
                start = datetime.datetime.utcnow()
                with fits.open(loadpath) as hdulist:
                    # Take a copy of the primary HDU so that it remains
                    # available in memory after the file has been closed
                    # pylint: disable=no-member
                    frame = fits.PrimaryHDU(hdulist[0].data, hdulist[0].header)
                    # pylint: enable=no-member
                    print('loaded frame ' + loadpath)

                    steps = ['headers']
                    filename = ''
                    if self._output_save_to_disk[camera_id]:
                        date = datetime.datetime.strptime(frame.header['DATE-OBS'],
                                                          '%Y-%m-%dT%H:%M:%S.%f')
                        ext = '.fits.gz' if self._compression_enabled else '.fits'
                        filename = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + ext

                    self.__move_bscale_bzero(frame)
                    self.__add_telescope_header(frame)
                    self.__add_environment_header(frame)
                    self.__add_pipeline_header(camera_id, frame, filename)

                    if self._intensity_stats_enabled:
                        self.__add_intensity_stats_header(frame)
                        steps.append('intstats')

                    objects = None
                    if self._hfd_enabled or self._wcs_enabled:
                        objects = self.__detect_objects(frame)
                        steps.append('objdetect')

                    if self._hfd_enabled:
                        self.__add_hfd_header(frame, objects)
                        steps.append('hfd')

                    # Update previews before the relatively-slow WCS step
                    annotations = self.__generate_header_annotations(camera_id, frame, objects)
                    self._preview_data.put((camera_id, frame, annotations))

                    if self._wcs_enabled:
                        wcs = self.__add_wcs_header(frame, camera_id, objects)
                        self._preview_data.put((camera_id, frame, wcs))
                        steps.append('wcs')

                    if self._output_save_to_disk[camera_id]:
                        tmp = '.tmp.fits.gz' if self._compression_enabled else '.tmp.fits'
                        tmpname = self._output_frame_prefix + '-' + camera_id + '-' + \
                            date.strftime('%Y%m%d%H%M%S%f')[:-3] + tmp

                        tmppath = str(self._output_directory / tmpname)
                        savepath = str(self._output_directory / filename)

                        # Simulate an atomic write by writing to a temporary file then renaming
                        frame.writeto(tmppath, overwrite=True)
                        shutil.move(tmppath, savepath)

                        print('Saved frame ' + filename)
                        log.info(LOG_NAME, 'Saved frame ' + filename)
                        steps.append('compress' if self._compression_enabled else 'save')
                        self.__save_config()

                    if self._dashboard_enabled:
                        self.__update_dashboard(camera_id, frame)
                        steps.append('dashboard')

                    self.__notify_opsd(frame)
                process_time = round((datetime.datetime.utcnow() - start).total_seconds(), 1)
                print('processed ' + loadpath + ' in ' + str(round(process_time, 2)) + 's (' \
                      + ', '.join(steps) + ')')

            except Exception:
                print('Unexpected exception while processing ' + loadpath + ':')
                traceback.print_exc(file=sys.stdout)
            finally:
                try:
                    os.remove(loadpath)
                    print('Deleting temporary frame: ' + loadpath)
                except Exception:
                    print('Failed to delete temporary frame: ' + loadpath)
                process_queue.task_done()

    @Pyro4.expose
    def notify_frame(self, camera_id, path):
        """Called by the camera daemons to notify that a new frame has been saved to disk"""
        if not pyro_client_matches(NOTIFY_FRAME_IPS):
            return CommandStatus.InvalidControlIP

        print(camera_id, path)
        if camera_id not in self._process_queue:
            raise Exception('Unknown camera id ' + camera_id)

        # Block until the processing thread has completed the previous frame.
        # We require a direct hand-off from the camera to the pipeline to prevent accidental
        # backlogs which would desync the real-time processing done by the processing thread.
        process_queue = self._process_queue[camera_id]
        wait_start = datetime.datetime.utcnow()
        process_queue.join()
        process_queue.put(path)
        wait = (datetime.datetime.utcnow() - wait_start).total_seconds()

        if wait > 0.1:
            print('WARNING: ' + camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')
            log.warning(LOG_NAME, camera_id + ' camera blocked for ' + str(wait) + 's by pipeline')

        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive_directory(self, directory):
        """Sets the output frame directory"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            directory_status = self.__set_archive_directory(directory)
            if directory_status != CommandStatus.Succeeded:
                return directory_status

            log.info(LOG_NAME, 'Frame archive directory set to ' + str(self._output_directory))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_output_frame_prefix(self, prefix):
        """Sets the output frame prefix"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_frame_prefix = prefix

            log.info(LOG_NAME, 'Frame prefix set to ' + prefix)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_archive(self, camera_id, enabled):
        """Enable or disable archiving to disk"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._output_save_to_disk[camera_id] = enabled
            log.info(LOG_NAME, 'Frame archiving for ' + camera_id \
                             + (' enabled' if enabled else ' disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def register_preview(self, camera_id, address):
        """Register a ds9 window for previews"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._ds9_preview_addresses[camera_id].append(address)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_object(self, object_name):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_object = object_name

            log.info(LOG_NAME, 'Frame object set to ' + object_name)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_frame_type(self, frame_type):
        """Sets the output frame number"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._frame_type = frame_type

            log.info(LOG_NAME, 'Frame type set to ' + frame_type)
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_min_threshold(self, percent):
        """Sets the minimum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_min_threshold = percent
        log.info(LOG_NAME, 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_max_threshold(self, percent):
        """Sets the maximum contrast percentage for the web dashboard preview"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_max_threshold = percent
        log.info(LOG_NAME, 'Dashboard preview min threshold set to ' + str(percent) + '%')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_thumb_size(self, max_size):
        """Sets the maximum dimension of the web dashboard preview thumbnails"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_thumb_size = max_size
        log.info(LOG_NAME, 'Dashboard preview thumbnail size set to ' + str(max_size) + ' px')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard_clip_size(self, size):
        """Sets the maximum dimension of the web dashboard clip region"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        self._dashboard_clip_size = size
        log.info(LOG_NAME, 'Dashboard preview clip size set to ' + str(size) + ' px')
        self.__save_config()
        return CommandStatus.Succeeded

    @Pyro4.expose
    def set_wcs(self, enabled):
        """Enable or disable wcs solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._wcs_enabled = enabled
            log.info(LOG_NAME, 'WCS solution ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_hfd(self, enabled):
        """Enable or disable half-flux diameter calculations"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._hfd_enabled = enabled
            log.info(LOG_NAME, 'HFD calculation ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_intensity_stats(self, enabled):
        """Enable or disable intensity statistics solutions"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._intensity_stats_enabled = enabled
            log.info(LOG_NAME, 'Intensity statistics ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_dashboard(self, enabled):
        """Enable or disable dashboard updates"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._dashboard_enabled = enabled
            log.info(LOG_NAME, 'Dashboard updates ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def set_compression(self, enabled):
        """Enable or disable gz compression"""
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            self._compression_enabled = enabled
            log.info(LOG_NAME, 'Frame compression ' + ('enabled' if enabled else 'disabled'))
            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def configure(self, params, quiet=False):
        """Set pipeline configuration to the requested state
           params should be a dictionary with the following keys:
              path: Path where images should be saved
              prefix: Filename prefix for each image
              type: Science/Calibration/Junk/etc
              object: Object name to include for Science frames
              archive: Dictionary of instrument arm to bool for which images to archive
              wcs: Attempt to solve WCS coordinates (True/False)
              intstats: Calculate basic intensity statistics (True/False)
              hfd: Calculate median half-flux diameters from objects in the image (True/False)
              compression: Save frames with gz compression (True/False)
           Any properties not specified in params will be reset to its default
        """
        if not pyro_client_matches(CONTROL_IPS):
            return CommandStatus.InvalidControlIP

        with TryLock(self._command_lock) as success:
            if not success:
                return CommandStatus.Blocked

            directory_status = self.__set_archive_directory(params.get('path', 'default'))
            if directory_status != CommandStatus.Succeeded:
                return directory_status

            if not quiet:
                log.info(LOG_NAME, 'Frame archive directory set to ' + str(self._output_directory))

            self._output_frame_prefix = params.get('prefix', 'unknown')
            if not quiet:
                log.info(LOG_NAME, 'Frame prefix set to ' + self._output_frame_prefix)

            self._frame_type = params.get('type', 'JUNK')
            if not quiet:
                log.info(LOG_NAME, 'Frame type set to ' + self._frame_type)

            self._frame_object = params.get('object', '')
            if not quiet:
                log.info(LOG_NAME, 'Frame object set to ' + self._frame_object)

            for k, v in params.get('archive', {c: False for c in CAMERAS}).items():
                self._output_save_to_disk[k] = v
                if not quiet:
                    log.info(LOG_NAME, 'Frame archiving for ' + k + \
                        (' enabled' if v else ' disabled'))

            self._wcs_enabled = params.get('wcs', False)
            if not quiet:
                log.info(LOG_NAME, 'WCS solution ' + \
                    ('enabled' if self._wcs_enabled else 'disabled'))

            self._intensity_stats_enabled = params.get('intstats', False)
            if not quiet:
                log.info(LOG_NAME, 'Intensity statistics ' + \
                    ('enabled' if self._intensity_stats_enabled else 'disabled'))

            self._hfd_enabled = params.get('hfd', False)
            if not quiet:
                log.info(LOG_NAME, 'HFD calculation ' + \
                    ('enabled' if self._hfd_enabled else 'disabled'))

            self._compression_enabled = params.get('compression', False)
            if not quiet:
                log.info(LOG_NAME, 'Frame compression ' + \
                    ('enabled' if self._compression_enabled else 'disabled'))

            self.__save_config()
            return CommandStatus.Succeeded

    @Pyro4.expose
    def report_status(self):
        """Returns a dictionary containing the current pipeline state"""
        return {
            'wcs_enabled': self._wcs_enabled,
            'hfd_enabled': self._hfd_enabled,
            'intensity_stats_enabled': self._intensity_stats_enabled,
            'dashboard_enabled': self._dashboard_enabled,
            'compression_enabled': self._compression_enabled,

            'archive_enabled': self._output_save_to_disk,
            'archive_directory': str(self._output_directory),

            'dashboard_min_threshold': self._dashboard_min_threshold,
            'dashboard_max_threshold': self._dashboard_max_threshold,
            'dashboard_thumb_size': self._dashboard_thumb_size,
            'dashboard_clip_size': self._dashboard_clip_size,

            'frame_type': self._frame_type,
            'frame_object': self._frame_object,
            'frame_prefix': self._output_frame_prefix
        }

if __name__ == '__main__':
    daemons.rasa_pipeline.launch(PipelineDaemon())
